{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13793974,"sourceType":"datasetVersion","datasetId":8781989},{"sourceId":13817658,"sourceType":"datasetVersion","datasetId":8799193}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport time\nimport io\nimport copy\nimport numpy as np\nimport pandas as pd\nimport gcsfs\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, mean_absolute_error","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:28.527734Z","iopub.execute_input":"2025-12-02T15:30:28.528581Z","iopub.status.idle":"2025-12-02T15:30:37.475127Z","shell.execute_reply.started":"2025-12-02T15:30:28.528544Z","shell.execute_reply":"2025-12-02T15:30:37.474552Z"},"editable":false},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nINPUT_SIZE = 224\nNORM_MEAN = [0.485, 0.456, 0.406]\nNORM_STD = [0.229, 0.224, 0.225]\n\n\n# Define your GCS variables\nproject_id = \"josiahs-project-475720\"\nbucket = \"calorie-prediction\"\nos.environ[\"GOOGLE_CLOUD_PROJECT\"] = project_id\n\nSA_KEY_FILE = \"/kaggle/input/my-kaggle-gcs-key/josiahs-project-475720-0a3d6753bc40.json\"\n\nif os.path.exists(SA_KEY_FILE):\n    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SA_KEY_FILE\n    print(f\"GOOGLE_APPLICATION_CREDENTIALS set to {SA_KEY_FILE}.\")\nelse:\n    print(f\"⚠️ Service account key '{SA_KEY_FILE}' not found. Please upload it to your Kaggle environment.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.476220Z","iopub.execute_input":"2025-12-02T15:30:37.476641Z","iopub.status.idle":"2025-12-02T15:30:37.572275Z","shell.execute_reply.started":"2025-12-02T15:30:37.476621Z","shell.execute_reply":"2025-12-02T15:30:37.571655Z"},"editable":false},"outputs":[{"name":"stdout","text":"GOOGLE_APPLICATION_CREDENTIALS set to /kaggle/input/my-kaggle-gcs-key/josiahs-project-475720-0a3d6753bc40.json.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"metadata_path = \"/kaggle/input/metadata/final_metadata_with_clusters.csv\"\nclean_df = pd.read_csv(metadata_path)\nclean_df['image_file'] = 'gs://' + bucket + '/' + clean_df['image_file']\n\nprint(\"Metadata loaded successfully.\")\n\n# Data Split\ntrain_df, temp_df = train_test_split(\n    clean_df,\n    test_size=0.2,\n    stratify=clean_df[\"meal_type_class\"],\n    random_state=42,\n    shuffle=True\n)\nval_df, test_df = train_test_split(\n    temp_df,\n    test_size=0.5,\n    random_state=42,\n    shuffle=True\n)\nprint(f\"\\nTraining Samples: {len(train_df)}\")\nprint(f\"Validation Samples: {len(val_df)}\")\nprint(f\"Testing Samples: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.573148Z","iopub.execute_input":"2025-12-02T15:30:37.573457Z","iopub.status.idle":"2025-12-02T15:30:37.629986Z","shell.execute_reply.started":"2025-12-02T15:30:37.573433Z","shell.execute_reply":"2025-12-02T15:30:37.629382Z"},"editable":false},"outputs":[{"name":"stdout","text":"Metadata loaded successfully.\n\nTraining Samples: 2463\nValidation Samples: 308\nTesting Samples: 308\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"clean_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.630634Z","iopub.execute_input":"2025-12-02T15:30:37.630865Z","iopub.status.idle":"2025-12-02T15:30:37.650773Z","shell.execute_reply.started":"2025-12-02T15:30:37.630842Z","shell.execute_reply":"2025-12-02T15:30:37.650184Z"},"editable":false},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"           dish_id  total_weight_g  total_calories      g_fat     g_carb  \\\n0  dish_1561662216      300.794281           193.0  12.387489  28.218290   \n1  dish_1561662054      419.438782           292.0  23.838249  26.351543   \n2  dish_1562008979      382.936646           290.0  22.224644  10.173570   \n3  dish_1560455030       20.590000           103.0   0.148000   4.625000   \n4  dish_1558372433       74.360001           143.0   0.286000   0.429000   \n\n   g_protein                                         image_file  \\\n0  18.633970  gs://calorie-prediction/nutrition5k_data/image...   \n1  25.910593  gs://calorie-prediction/nutrition5k_data/image...   \n2  35.345387  gs://calorie-prediction/nutrition5k_data/image...   \n3   0.956000  gs://calorie-prediction/nutrition5k_data/image...   \n4  20.020000  gs://calorie-prediction/nutrition5k_data/image...   \n\n   meal_type_class     meal_type_name  \n0                4              Salad  \n1                4              Salad  \n2                4              Salad  \n3                2            Dessert  \n4                5  Sandwich / Burger  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dish_id</th>\n      <th>total_weight_g</th>\n      <th>total_calories</th>\n      <th>g_fat</th>\n      <th>g_carb</th>\n      <th>g_protein</th>\n      <th>image_file</th>\n      <th>meal_type_class</th>\n      <th>meal_type_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>dish_1561662216</td>\n      <td>300.794281</td>\n      <td>193.0</td>\n      <td>12.387489</td>\n      <td>28.218290</td>\n      <td>18.633970</td>\n      <td>gs://calorie-prediction/nutrition5k_data/image...</td>\n      <td>4</td>\n      <td>Salad</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>dish_1561662054</td>\n      <td>419.438782</td>\n      <td>292.0</td>\n      <td>23.838249</td>\n      <td>26.351543</td>\n      <td>25.910593</td>\n      <td>gs://calorie-prediction/nutrition5k_data/image...</td>\n      <td>4</td>\n      <td>Salad</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dish_1562008979</td>\n      <td>382.936646</td>\n      <td>290.0</td>\n      <td>22.224644</td>\n      <td>10.173570</td>\n      <td>35.345387</td>\n      <td>gs://calorie-prediction/nutrition5k_data/image...</td>\n      <td>4</td>\n      <td>Salad</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>dish_1560455030</td>\n      <td>20.590000</td>\n      <td>103.0</td>\n      <td>0.148000</td>\n      <td>4.625000</td>\n      <td>0.956000</td>\n      <td>gs://calorie-prediction/nutrition5k_data/image...</td>\n      <td>2</td>\n      <td>Dessert</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>dish_1558372433</td>\n      <td>74.360001</td>\n      <td>143.0</td>\n      <td>0.286000</td>\n      <td>0.429000</td>\n      <td>20.020000</td>\n      <td>gs://calorie-prediction/nutrition5k_data/image...</td>\n      <td>5</td>\n      <td>Sandwich / Burger</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\nprint(train_df['meal_type_class'].value_counts())\n\nimport matplotlib.pyplot as plt\nfor cls in sorted(train_df['meal_type_class'].unique())[:10]:\n    row = train_df[train_df['meal_type_class']==cls].sample(1).iloc[0]\n    print(cls, row['meal_type_name'], row['image_file'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.652393Z","iopub.execute_input":"2025-12-02T15:30:37.652899Z","iopub.status.idle":"2025-12-02T15:30:37.670674Z","shell.execute_reply.started":"2025-12-02T15:30:37.652882Z","shell.execute_reply":"2025-12-02T15:30:37.670008Z"},"editable":false},"outputs":[{"name":"stdout","text":"meal_type_class\n4    528\n8    310\n3    275\n7    272\n6    243\n0    237\n2    222\n1    148\n5    122\n9    106\nName: count, dtype: int64\n0 Rice Bowl gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1565107066/rgb.png\n1 Pasta gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1574193262/rgb.png\n2 Dessert gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1559838402/rgb.png\n3 Soup gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1566588016/rgb.png\n4 Salad gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1565637548/rgb.png\n5 Sandwich / Burger gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1558372650/rgb.png\n6 Vegetable Plate gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1559062005/rgb.png\n7 Meat / Protein Plate gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1565711154/rgb.png\n8 Breakfast Items gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1563464670/rgb.png\n9 Mixed Plates / Stews gs://calorie-prediction/nutrition5k_data/imagery/realsense_overhead/dish_1564427406/rgb.png\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class NutritionDataset(Dataset):\n    def __init__(self, df, bucket, gcs_token=None, transform=None,\n                 cal_mean=0.0, cal_std=1.0, macro_means=None, macro_stds=None):\n\n        self.df = df.reset_index(drop=True).copy()\n        self.bucket = bucket.replace(\"gs://\", \"\").strip(\"/\")\n        self.gcs_token = gcs_token\n        self.transform = transform\n        self.fs = None\n\n        # store scaling\n        self.cal_mean = cal_mean\n        self.cal_std = cal_std\n        self.macro_means = np.array(macro_means, dtype=np.float32)\n        self.macro_stds = np.array(macro_stds, dtype=np.float32)\n\n    def _init_fs(self):\n        if self.fs is None:\n            if self.gcs_token:\n                self.fs = gcsfs.GCSFileSystem(token=self.gcs_token)\n            else:\n                self.fs = gcsfs.GCSFileSystem(token=\"anon\")\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        self._init_fs()\n\n        row = self.df.iloc[idx]\n        img_path = row[\"image_file\"]\n\n        clean = img_path.replace(\"gs://calorie-prediction/\", \"\").lstrip(\"/\")\n        gcs_full_path = f\"gs://calorie-prediction/{clean}\"\n\n        # Load image\n        try:\n            with self.fs.open(gcs_full_path, \"rb\") as f:\n                image = Image.open(f).convert(\"RGB\")\n        except Exception as e:\n            print(f\"[WARN] Could not load {gcs_full_path}: {e}\")\n            raise\n\n        if self.transform:\n            image = self.transform(image)\n\n        # ---- SCALE TARGETS HERE ----\n        cal_scaled = (float(row[\"total_calories\"]) - self.cal_mean) / self.cal_std\n\n        mac_scaled = np.array([\n            (float(row[\"g_protein\"]) - self.macro_means[0]) / self.macro_stds[0],\n            (float(row[\"g_carb\"])    - self.macro_means[1]) / self.macro_stds[1],\n            (float(row[\"g_fat\"])     - self.macro_means[2]) / self.macro_stds[2],\n        ], dtype=np.float32)\n\n        targets = {\n            \"class\": int(row[\"meal_type_class\"]),\n            \"calories\": torch.tensor(cal_scaled, dtype=torch.float32),\n            \"macros\": torch.tensor(mac_scaled, dtype=torch.float32)\n        }\n\n        return image, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.671389Z","iopub.execute_input":"2025-12-02T15:30:37.671606Z","iopub.status.idle":"2025-12-02T15:30:37.680131Z","shell.execute_reply.started":"2025-12-02T15:30:37.671580Z","shell.execute_reply":"2025-12-02T15:30:37.679535Z"},"editable":false},"outputs":[],"execution_count":6},{"cell_type":"code","source":"NUM_CLASSES = 10  \nBATCH_SIZE = 32\nFREEZE_EPOCHS = 4\nFINETUNE_EPOCHS = 12\nLR_FREEZE = 3e-4\nLR_FINETUNE = 1e-5\nIMG_SIZE = 384","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.680694Z","iopub.execute_input":"2025-12-02T15:30:37.680930Z","iopub.status.idle":"2025-12-02T15:30:37.698112Z","shell.execute_reply.started":"2025-12-02T15:30:37.680906Z","shell.execute_reply":"2025-12-02T15:30:37.697538Z"},"editable":false},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from google.cloud import storage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:37.698771Z","iopub.execute_input":"2025-12-02T15:30:37.699007Z","iopub.status.idle":"2025-12-02T15:30:52.244103Z","shell.execute_reply.started":"2025-12-02T15:30:37.698986Z","shell.execute_reply":"2025-12-02T15:30:52.243532Z"},"editable":false},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_tf = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.08, contrast=0.08, saturation=0.08, hue=0.02),\n    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.1,2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])\nval_tf = transforms.Compose([\n    transforms.Resize(int(IMG_SIZE*1.14)),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:52.245611Z","iopub.execute_input":"2025-12-02T15:30:52.246021Z","iopub.status.idle":"2025-12-02T15:30:52.251357Z","shell.execute_reply.started":"2025-12-02T15:30:52.246002Z","shell.execute_reply":"2025-12-02T15:30:52.250690Z"},"editable":false},"outputs":[],"execution_count":9},{"cell_type":"code","source":"GCS_TOKEN_PATH = \"/kaggle/input/my-kaggle-gcs-key/josiahs-project-475720-0a3d6753bc40.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:55.792390Z","iopub.execute_input":"2025-12-02T15:30:55.793064Z","iopub.status.idle":"2025-12-02T15:30:55.796216Z","shell.execute_reply.started":"2025-12-02T15:30:55.793039Z","shell.execute_reply":"2025-12-02T15:30:55.795587Z"},"editable":false},"outputs":[],"execution_count":10},{"cell_type":"code","source":"cal_mean = train_df['total_calories'].mean()\ncal_std  = train_df['total_calories'].std()\nmacro_means = train_df[['g_fat','g_carb','g_protein']].mean().values\nmacro_stds  = train_df[['g_fat','g_carb','g_protein']].std().values\n\nprint(\"cal mean/std:\", cal_mean, cal_std)\nprint(\"macro means:\", macro_means, \"macro stds:\", macro_stds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:30:57.769986Z","iopub.execute_input":"2025-12-02T15:30:57.770471Z","iopub.status.idle":"2025-12-02T15:30:57.780174Z","shell.execute_reply.started":"2025-12-02T15:30:57.770443Z","shell.execute_reply":"2025-12-02T15:30:57.779355Z"},"editable":false},"outputs":[{"name":"stdout","text":"cal mean/std: 192.18026796589524 141.41432514790083\nmacro means: [10.63356507 16.83611963 14.23756943] macro stds: [12.95014584 15.74015911 17.50638443]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import os, io, time\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torchvision import transforms, models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, accuracy_score\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:31:01.972447Z","iopub.execute_input":"2025-12-02T15:31:01.972827Z","iopub.status.idle":"2025-12-02T15:31:01.977906Z","shell.execute_reply.started":"2025-12-02T15:31:01.972802Z","shell.execute_reply":"2025-12-02T15:31:01.977136Z"},"editable":false},"outputs":[],"execution_count":12},{"cell_type":"code","source":"USE_GCS = True\ntrain_ds = NutritionDataset(train_df,\n                           bucket=(bucket if USE_GCS else None),\n                           gcs_token=(GCS_TOKEN_PATH if USE_GCS else None),\n                           transform=train_tf,\n                           cal_mean=cal_mean, cal_std=cal_std,\n                           macro_means=macro_means, macro_stds=macro_stds)\n\nval_ds = NutritionDataset(val_df,\n                           bucket=(bucket if USE_GCS else None),\n                           gcs_token=(GCS_TOKEN_PATH if USE_GCS else None),\n                           transform=val_tf,\n                           cal_mean=cal_mean, cal_std=cal_std,\n                           macro_means=macro_means, macro_stds=macro_stds)\n\ntest_ds = NutritionDataset(test_df, \n                           bucket=(bucket if USE_GCS else None),\n                           gcs_token=(GCS_TOKEN_PATH if USE_GCS else None),\n                           transform=val_tf,\n                           cal_mean=cal_mean, cal_std=cal_std,\n                           macro_means=macro_means, macro_stds=macro_stds)\n\nclass_counts = train_df['meal_type_class'].value_counts().sort_index()\n\nsample_weights = train_df['meal_type_class'].map(lambda c: 1.0/float(class_counts[c])).values\nsampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS, pin_memory=True)\nval_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\ntest_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\nprint(\"Dataloaders ready (BATCH_SIZE=%d)\"%BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:34:49.830673Z","iopub.execute_input":"2025-12-02T15:34:49.831420Z","iopub.status.idle":"2025-12-02T15:34:49.848122Z","shell.execute_reply.started":"2025-12-02T15:34:49.831395Z","shell.execute_reply":"2025-12-02T15:34:49.847417Z"},"editable":false},"outputs":[{"name":"stdout","text":"Dataloaders ready (BATCH_SIZE=24)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import torchvision\nmodel = torchvision.models.resnet50(weights=\"IMAGENET1K_V2\")\nmodel.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\nmodel = model.to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:34:57.733111Z","iopub.execute_input":"2025-12-02T15:34:57.733911Z","iopub.status.idle":"2025-12-02T15:34:58.150134Z","shell.execute_reply.started":"2025-12-02T15:34:57.733878Z","shell.execute_reply":"2025-12-02T15:34:58.149357Z"},"editable":false},"outputs":[],"execution_count":29},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nuser_credential = user_secrets.get_gcloud_credential()\nuser_secrets.set_tensorflow_credential(user_credential)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:34:58.591330Z","iopub.execute_input":"2025-12-02T15:34:58.591806Z","iopub.status.idle":"2025-12-02T15:34:58.713905Z","shell.execute_reply.started":"2025-12-02T15:34:58.591781Z","shell.execute_reply":"2025-12-02T15:34:58.713351Z"},"editable":false},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from google.cloud import storage\nfrom sklearn.utils.class_weight import compute_class_weight\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:34:59.089838Z","iopub.execute_input":"2025-12-02T15:34:59.090434Z","iopub.status.idle":"2025-12-02T15:34:59.093917Z","shell.execute_reply.started":"2025-12-02T15:34:59.090412Z","shell.execute_reply":"2025-12-02T15:34:59.093149Z"},"editable":false},"outputs":[],"execution_count":31},{"cell_type":"code","source":"weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.arange(NUM_CLASSES),\n    y=train_df[\"meal_type_class\"]\n)\n\nweights = torch.tensor(weights).float().to(DEVICE)\ncriterion = nn.CrossEntropyLoss(weight=weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:34:59.517966Z","iopub.execute_input":"2025-12-02T15:34:59.518635Z","iopub.status.idle":"2025-12-02T15:34:59.524569Z","shell.execute_reply.started":"2025-12-02T15:34:59.518609Z","shell.execute_reply":"2025-12-02T15:34:59.523813Z"},"editable":false},"outputs":[],"execution_count":32},{"cell_type":"code","source":"NUM_CLASSES = 10\nBATCH_SIZE = 24           \nIMG_SIZE = 448      \nFREEZE_EPOCHS = 5\nFINETUNE_EPOCHS = 18\nLR_HEAD = 3e-4\nLR_FINETUNE = 1e-5\nWEIGHT_DECAY = 1e-5\nNUM_WORKERS = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:00.240818Z","iopub.execute_input":"2025-12-02T15:35:00.241356Z","iopub.status.idle":"2025-12-02T15:35:00.245146Z","shell.execute_reply.started":"2025-12-02T15:35:00.241329Z","shell.execute_reply":"2025-12-02T15:35:00.244367Z"},"editable":false},"outputs":[],"execution_count":33},{"cell_type":"code","source":"print(\"Sizes -> train:\", len(train_df), \"val:\", len(val_df), \"test:\", len(test_df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:00.616528Z","iopub.execute_input":"2025-12-02T15:35:00.617085Z","iopub.status.idle":"2025-12-02T15:35:00.621186Z","shell.execute_reply.started":"2025-12-02T15:35:00.617065Z","shell.execute_reply":"2025-12-02T15:35:00.620551Z"},"editable":false},"outputs":[{"name":"stdout","text":"Sizes -> train: 2463 val: 308 test: 308\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"GCS_TOKEN_PATH = \"/kaggle/input/my-kaggle-gcs-key/josiahs-project-475720-0a3d6753bc40.json\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:01.080446Z","iopub.execute_input":"2025-12-02T15:35:01.081005Z","iopub.status.idle":"2025-12-02T15:35:01.084132Z","shell.execute_reply.started":"2025-12-02T15:35:01.080984Z","shell.execute_reply":"2025-12-02T15:35:01.083346Z"},"editable":false},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class ThreeHeadResNet(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        base = models.resnet50(pretrained=True)\n        self.features = nn.Sequential(*list(base.children())[:-1])\n        feature_size = base.fc.in_features\n\n        self.cls_head = nn.Sequential(\n            nn.Linear(feature_size, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n        self.cal_head = nn.Sequential(\n            nn.Linear(feature_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 1)\n        )\n        self.mac_head = nn.Sequential(\n            nn.Linear(feature_size, 256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, 3)\n        )\n\n    def forward(self, x):\n        f = self.features(x)            \n        f = f.view(f.size(0), -1)       \n        c = self.cls_head(f)\n        cal = self.cal_head(f).squeeze(1)  \n        mac = self.mac_head(f)            \n        return c, cal, mac\n\nmodel = ThreeHeadResNet(num_classes=NUM_CLASSES).to(DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:01.595907Z","iopub.execute_input":"2025-12-02T15:35:01.596182Z","iopub.status.idle":"2025-12-02T15:35:02.029230Z","shell.execute_reply.started":"2025-12-02T15:35:01.596163Z","shell.execute_reply":"2025-12-02T15:35:02.028427Z"},"jupyter":{"source_hidden":true},"editable":false},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"cls_weights = compute_class_weight(class_weight='balanced', classes=np.arange(NUM_CLASSES), y=train_df['meal_type_class'])\ncls_weights = torch.tensor(cls_weights, dtype=torch.float32).to(DEVICE)\ncls_loss_fn = nn.CrossEntropyLoss(weight=cls_weights)\n\nreg_loss_fn = nn.SmoothL1Loss()\n\nCLS_W = 1.0\nCAL_W = 3.0  \nMAC_W = 2.0  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:02.250611Z","iopub.execute_input":"2025-12-02T15:35:02.251251Z","iopub.status.idle":"2025-12-02T15:35:02.257152Z","shell.execute_reply.started":"2025-12-02T15:35:02.251229Z","shell.execute_reply":"2025-12-02T15:35:02.256566Z"},"editable":false},"outputs":[],"execution_count":37},{"cell_type":"code","source":"\ndef unscale_calories(preds_scaled, mean, std):\n    return preds_scaled * std + mean\ndef unscale_macros(preds_scaled, means, stds):\n    return preds_scaled * stds + means\ndef evaluate_model(model, loader, cal_mean, cal_std, macro_means, macro_stds):\n    model.eval()\n    all_true_cls, all_pred_cls = [], []\n    all_true_cal, all_pred_cal = [], []\n    all_true_mac, all_pred_mac = [], []\n    with torch.no_grad():\n        for imgs, targets in loader:\n            cls_labels = targets[\"class\"].to(DEVICE)\n            cal_scaled = targets[\"calories\"].to(DEVICE)\n            mac_scaled = targets[\"macros\"].to(DEVICE)\n            imgs = imgs.to(DEVICE)\n\n            c_out, cal_out, mac_out = model(imgs)\n            preds_cls = torch.argmax(c_out, dim=1)\n\n            all_true_cls.append(cls_labels.cpu().numpy())\n            all_pred_cls.append(preds_cls.cpu().numpy())\n\n            all_true_cal.append(unscale_calories(cal_scaled.cpu().numpy(), cal_mean, cal_std))\n            all_pred_cal.append(unscale_calories(cal_out.cpu().numpy(), cal_mean, cal_std))\n\n            all_true_mac.append(unscale_macros(mac_scaled.cpu().numpy(), macro_means, macro_stds))\n            all_pred_mac.append(unscale_macros(mac_out.cpu().numpy(), macro_means, macro_stds))\n    all_true_cls = np.concatenate(all_true_cls)\n    all_pred_cls = np.concatenate(all_pred_cls)\n    all_true_cal = np.concatenate(all_true_cal)\n    all_pred_cal = np.concatenate(all_pred_cal)\n    all_true_mac = np.concatenate(all_true_mac)\n    all_pred_mac = np.concatenate(all_pred_mac)\n    acc = accuracy_score(all_true_cls, all_pred_cls)\n    cal_mae = mean_absolute_error(all_true_cal, all_pred_cal)\n    mac_mae = mean_absolute_error(all_true_mac.reshape(-1,3), all_pred_mac.reshape(-1,3))\n    return acc, cal_mae, mac_mae, (all_true_cls, all_pred_cls, all_true_cal, all_pred_cal, all_true_mac, all_pred_mac)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:03.497844Z","iopub.execute_input":"2025-12-02T15:35:03.498109Z","iopub.status.idle":"2025-12-02T15:35:03.505837Z","shell.execute_reply.started":"2025-12-02T15:35:03.498089Z","shell.execute_reply":"2025-12-02T15:35:03.505092Z"},"editable":false},"outputs":[],"execution_count":38},{"cell_type":"code","source":"SAVE_DIR = \"/kaggle/working\"\nos.makedirs(SAVE_DIR, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:07.112262Z","iopub.execute_input":"2025-12-02T15:35:07.112766Z","iopub.status.idle":"2025-12-02T15:35:07.116424Z","shell.execute_reply.started":"2025-12-02T15:35:07.112744Z","shell.execute_reply":"2025-12-02T15:35:07.115695Z"},"editable":false},"outputs":[],"execution_count":39},{"cell_type":"code","source":"cls_criterion = nn.CrossEntropyLoss()\ncal_criterion = nn.MSELoss() \nmac_criterion = nn.MSELoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:07.671583Z","iopub.execute_input":"2025-12-02T15:35:07.671848Z","iopub.status.idle":"2025-12-02T15:35:07.675514Z","shell.execute_reply.started":"2025-12-02T15:35:07.671828Z","shell.execute_reply":"2025-12-02T15:35:07.674863Z"},"editable":false},"outputs":[],"execution_count":40},{"cell_type":"code","source":"CLS_W = 1.0\nCAL_W = 1.0\nMAC_W = 1.0\nCLIP_NORM = 1.0\nPATIENCE = 6\nSAVE_DIR = \"/kaggle/working/checkpoints\" \nos.makedirs(SAVE_DIR, exist_ok=True)\n\ncls_criterion = nn.CrossEntropyLoss()\nreg_criterion = nn.MSELoss()\n\nmodel = model.to(DEVICE)\n\nscaler = torch.amp.GradScaler('cuda')\n\n# ---- Phase 1: freeze backbone, train heads only ----\nfor p in model.features.parameters():\n    p.requires_grad = False\n\nhead_params = list(model.cls_head.parameters()) + \\\n              list(model.cal_head.parameters()) + \\\n              list(model.mac_head.parameters())\n\nopt = optim.AdamW(head_params, lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n\nbest_val_loss = float(\"inf\")\nno_improve = 0\n\nprint(\"=== Phase 1: training heads only ===\")\nfor epoch in range(1, FREEZE_EPOCHS + 1):\n    model.train()\n    running_loss = 0.0\n    n_samples = 0\n    start = time.time()\n\n    for imgs, targets in train_loader:\n        imgs = imgs.to(DEVICE, non_blocking=True)\n        cls_labels = targets[\"class\"].long().to(DEVICE)\n        cal_targets = targets[\"calories\"].float().to(DEVICE)\n        mac_targets = targets[\"macros\"].float().to(DEVICE)\n\n        opt.zero_grad()\n        with torch.amp.autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n            cls_pred, cal_pred, mac_pred = model(imgs)\n            loss_cls = cls_criterion(cls_pred, cls_labels)\n            loss_cal = reg_criterion(cal_pred.squeeze(), cal_targets)\n            loss_mac = reg_criterion(mac_pred, mac_targets)\n            loss = CLS_W * loss_cls + CAL_W * loss_cal + MAC_W * loss_mac\n\n        scaler.scale(loss).backward()\n        # unscale gradients before clipping\n        scaler.unscale_(opt)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n        scaler.step(opt)\n        scaler.update()\n\n        running_loss += loss.item() * imgs.size(0)\n        n_samples += imgs.size(0)\n\n    train_loss = running_loss / max(1, n_samples)\n\n    # Evaluate (unscales internally)\n    val_acc, val_cal_mae, val_mac_mae, _ = evaluate_model(\n        model,\n        val_loader,\n        cal_mean=train_ds.cal_mean,\n        cal_std=train_ds.cal_std,\n        macro_means=train_ds.macro_means,\n        macro_stds=train_ds.macro_stds,\n    )\n\n    val_loss = CLS_W * 0.0 + CAL_W * val_cal_mae + MAC_W * val_mac_mae\n\n    print(f\"[Phase1] E{epoch}/{FREEZE_EPOCHS} train_loss={train_loss:.4f} val_acc={val_acc:.4f} \"\n          f\"val_cal_MAE={val_cal_mae:.2f} val_mac_MAE={val_mac_mae:.2f} time={time.time()-start:.1f}s\")\n\n    # Save best heads\n    if val_loss < best_val_loss - 1e-6:\n        best_val_loss = val_loss\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state\": model.state_dict(),\n            \"opt_state\": opt.state_dict(),\n            \"val_loss\": val_loss\n        }, os.path.join(SAVE_DIR, \"best_heads.pth\"))\n        no_improve = 0\n        print(\"  Saved best_heads.pth\")\n    else:\n        no_improve += 1\n        print(f\"  No improvement ({no_improve}/{PATIENCE})\")\n\n    if no_improve >= PATIENCE:\n        print(\"Early stopping in Phase 1.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T15:35:09.803039Z","iopub.execute_input":"2025-12-02T15:35:09.803291Z","iopub.status.idle":"2025-12-02T16:38:40.888880Z","shell.execute_reply.started":"2025-12-02T15:35:09.803274Z","shell.execute_reply":"2025-12-02T16:38:40.888188Z"},"editable":false},"outputs":[{"name":"stdout","text":"=== Phase 1: training heads only ===\n[Phase1] E1/5 train_loss=3.2090 val_acc=0.6039 val_cal_MAE=76.79 val_mac_MAE=9.45 time=840.0s\n  Saved best_heads.pth\n[Phase1] E2/5 train_loss=2.0695 val_acc=0.7045 val_cal_MAE=74.66 val_mac_MAE=9.40 time=751.1s\n  Saved best_heads.pth\n[Phase1] E3/5 train_loss=1.8726 val_acc=0.8084 val_cal_MAE=109.85 val_mac_MAE=9.21 time=756.3s\n  No improvement (1/6)\n[Phase1] E4/5 train_loss=1.6830 val_acc=0.7143 val_cal_MAE=77.90 val_mac_MAE=9.04 time=707.1s\n  No improvement (2/6)\n[Phase1] E5/5 train_loss=1.5954 val_acc=0.7727 val_cal_MAE=118.07 val_mac_MAE=9.11 time=756.1s\n  No improvement (3/6)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# ---- Phase 2: unfreeze entire model and finetune ----\nfor p in model.features.parameters():\n    p.requires_grad = True\n\nopt = optim.AdamW(model.parameters(), lr=LR_FINETUNE, weight_decay=WEIGHT_DECAY)\n# Use ReduceLROnPlateau that reacts to validation composite loss\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=2, verbose=True)\n\nbest_val_loss = float(\"inf\")\nno_improve = 0\n\nprint(\"=== Phase 2: finetune full model ===\")\nfor epoch in range(1, FINETUNE_EPOCHS + 1):\n    model.train()\n    running_loss = 0.0\n    n_samples = 0\n    start = time.time()\n\n    for imgs, targets in train_loader:\n        imgs = imgs.to(DEVICE, non_blocking=True)\n        cls_labels = targets[\"class\"].long().to(DEVICE)\n        cal_targets = targets[\"calories\"].float().to(DEVICE)\n        mac_targets = targets[\"macros\"].float().to(DEVICE)\n\n        opt.zero_grad()\n        with torch.amp.autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\n            cls_pred, cal_pred, mac_pred = model(imgs)\n            loss_cls = cls_criterion(cls_pred, cls_labels)\n            loss_cal = reg_criterion(cal_pred.squeeze(), cal_targets)\n            loss_mac = reg_criterion(mac_pred, mac_targets)\n            loss = CLS_W * loss_cls + CAL_W * loss_cal + MAC_W * loss_mac\n\n        scaler.scale(loss).backward()\n        scaler.unscale_(opt)\n        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM)\n        scaler.step(opt)\n        scaler.update()\n\n        running_loss += loss.item() * imgs.size(0)\n        n_samples += imgs.size(0)\n\n    train_loss = running_loss / max(1, n_samples)\n\n    # Evaluate on validation set (unscaled inside evaluate_model)\n    val_acc, val_cal_mae, val_mac_mae, _ = evaluate_model(\n        model,\n        val_loader,\n        cal_mean=train_ds.cal_mean,\n        cal_std=train_ds.cal_std,\n        macro_means=train_ds.macro_means,\n        macro_stds=train_ds.macro_stds,\n    )\n\n    val_loss = CLS_W * 0.0 + CAL_W * val_cal_mae + MAC_W * val_mac_mae\n\n    scheduler.step(val_loss)\n\n    print(f\"[Finetune] E{epoch}/{FINETUNE_EPOCHS} train_loss={train_loss:.4f} val_acc={val_acc:.4f} \"\n          f\"val_cal_MAE={val_cal_mae:.2f} val_mac_MAE={val_mac_mae:.2f} time={time.time()-start:.1f}s\")\n\n    if val_loss < best_val_loss - 1e-6:\n        best_val_loss = val_loss\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state\": model.state_dict(),\n            \"opt_state\": opt.state_dict(),\n            \"val_loss\": val_loss\n        }, os.path.join(SAVE_DIR, \"best_full.pth\"))\n        no_improve = 0\n        print(\"  Saved best_full.pth\")\n    else:\n        no_improve += 1\n        print(f\"  No improvement ({no_improve}/{PATIENCE})\")\n\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state\": model.state_dict(),\n        \"opt_state\": opt.state_dict(),\n        \"val_loss\": val_loss\n    }, os.path.join(SAVE_DIR, \"last_checkpoint.pth\"))\n\n    if no_improve >= PATIENCE:\n        print(\"Early stopping triggered.\")\n        break\n\nbest_ckpt = os.path.join(SAVE_DIR, \"best_full.pth\")\nif os.path.exists(best_ckpt):\n    ck = torch.load(best_ckpt, map_location=DEVICE)\n    model.load_state_dict(ck[\"model_state\"])\n    print(\"Loaded best_full.pth - training complete.\")\nelse:\n    print(\"No best_full.pth found; training finished with last checkpoint.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T16:39:27.450549Z","iopub.execute_input":"2025-12-02T16:39:27.451062Z","execution_failed":"2025-12-02T18:53:22.862Z"},"editable":false},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"=== Phase 2: finetune full model ===\n[Finetune] E1/18 train_loss=1.2496 val_acc=0.8506 val_cal_MAE=59.04 val_mac_MAE=7.53 time=721.4s\n  Saved best_full.pth\n[Finetune] E2/18 train_loss=1.0757 val_acc=0.8377 val_cal_MAE=60.37 val_mac_MAE=7.19 time=709.0s\n  No improvement (1/6)\n[Finetune] E3/18 train_loss=0.8954 val_acc=0.8539 val_cal_MAE=54.46 val_mac_MAE=6.85 time=709.8s\n  Saved best_full.pth\n[Finetune] E4/18 train_loss=0.8343 val_acc=0.8734 val_cal_MAE=54.59 val_mac_MAE=6.85 time=740.1s\n  No improvement (1/6)\n[Finetune] E5/18 train_loss=0.7574 val_acc=0.8961 val_cal_MAE=50.35 val_mac_MAE=6.71 time=800.6s\n  Saved best_full.pth\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# DIAGNOSTIC 1: show batch-level stats (scaled targets coming from dataset)\nimgs, targets = next(iter(train_loader))\nprint(\"SCALED targets (calories) — mean/std/min/max:\", \n      targets[\"calories\"].mean().item(), targets[\"calories\"].std().item(),\n      targets[\"calories\"].min().item(), targets[\"calories\"].max().item())\nprint(\"SCALED targets (macros) shape:\", targets[\"macros\"].shape,\n      \"mean/std:\", targets[\"macros\"].mean().item(), targets[\"macros\"].std().item())\n\n# DIAGNOSTIC 2: model outputs on same batch (scaled outputs)\nmodel.eval()\nwith torch.no_grad():\n    imgs = imgs.to(DEVICE)\n    c_out, cal_out, mac_out = model(imgs)\n    print(\"MODEL cal_out (scaled) — mean/std/min/max:\", \n          cal_out.mean().item(), cal_out.std().item(),\n          cal_out.min().item(), cal_out.max().item())\n    print(\"MODEL mac_out (scaled) — shape:\", mac_out.shape,\n          \"mean/std:\", mac_out.mean().item(), mac_out.std().item())\n\n# Also show a few unscaled comparisons\ncal_mean, cal_std = train_ds.cal_mean, train_ds.cal_std\nmacro_means, macro_stds = train_ds.macro_means, train_ds.macro_stds\ncal_true_unscaled = (targets[\"calories\"].cpu().numpy() * cal_std) + cal_mean\ncal_pred_unscaled = (cal_out.cpu().numpy() * cal_std) + cal_mean\nprint(\"Example unscaled true cal (first 5):\", cal_true_unscaled[:5])\nprint(\"Example unscaled pred cal (first 5):\", cal_pred_unscaled[:5])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T13:53:08.591090Z","iopub.execute_input":"2025-12-02T13:53:08.591770Z","iopub.status.idle":"2025-12-02T13:53:11.486270Z","shell.execute_reply.started":"2025-12-02T13:53:08.591747Z","shell.execute_reply":"2025-12-02T13:53:11.485605Z"},"editable":false},"outputs":[{"name":"stdout","text":"SCALED targets (calories) — mean/std/min/max: 180.29166666666666 168.2328818520086 17.0 706.0\nSCALED targets (macros) shape: torch.Size([24, 3]) mean/std: 12.130121231079102 16.383054733276367\nMODEL cal_out (scaled) — mean/std/min/max: 183.97021484375 167.00860595703125 28.373851776123047 638.457275390625\nMODEL mac_out (scaled) — shape: torch.Size([24, 3]) mean/std: 10.695490837097168 12.281275749206543\nExample unscaled true cal (first 5): [21545.7433653   2596.22379548  9808.35437802 21404.32904015\n 17020.48496057]\nExample unscaled pred cal (first 5): [25963.59    4204.6494  7588.83   20158.121  17797.52  ]\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"best_model_path = \"/kaggle/working/best_full.pth\"\n\ncheckpoint = torch.load(best_model_path, map_location=DEVICE)\nmodel.load_state_dict(checkpoint)\nmodel.to(DEVICE)\nmodel.eval()\n\nprint(\"Loaded best fine-tuned model ✔️\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T18:51:47.606856Z","iopub.execute_input":"2025-12-01T18:51:47.607562Z","iopub.status.idle":"2025-12-01T18:51:47.739202Z","shell.execute_reply.started":"2025-12-01T18:51:47.607539Z","shell.execute_reply":"2025-12-01T18:51:47.738505Z"},"editable":false},"outputs":[{"name":"stdout","text":"Loaded best fine-tuned model ✔️\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, mean_absolute_error\nimport numpy as np\n\ndef evaluate_model(model, test_loader):\n    model.eval()\n\n    all_true_cls, all_pred_cls = [], []\n    all_true_cal, all_pred_cal = [], []\n    all_true_mac, all_pred_mac = [], []\n\n    with torch.no_grad():\n        for images, class_labels, calories, macros in test_loader:\n            images = images.to(DEVICE)\n            class_labels = class_labels.to(DEVICE)\n            calories = calories.to(DEVICE)\n            macros = macros.to(DEVICE)\n\n            pred_cls, pred_cal, pred_mac = model(images)\n\n            all_true_cls.append(class_labels.cpu().numpy())\n            all_pred_cls.append(pred_cls.argmax(1).cpu().numpy())\n\n            all_true_cal.append(calories.cpu().numpy())\n            all_pred_cal.append(pred_cal.cpu().numpy())\n\n            all_true_mac.append(macros.cpu().numpy())\n            all_pred_mac.append(pred_mac.cpu().numpy())\n\n    all_true_cls = np.concatenate(all_true_cls)\n    all_pred_cls = np.concatenate(all_pred_cls)\n    all_true_cal = np.concatenate(all_true_cal).reshape(-1)\n    all_pred_cal = np.concatenate(all_pred_cal).reshape(-1)\n    all_true_mac = np.concatenate(all_true_mac)\n    all_pred_mac = np.concatenate(all_pred_mac)\n\n    print(\"========== TEST RESULTS ==========\")\n    print(f\"Classification Accuracy: {accuracy_score(all_true_cls, all_pred_cls):.4f}\")\n    print(f\"Calorie MAE: {mean_absolute_error(all_true_cal, all_pred_cal):.2f}\")\n    print(f\"Macros MAE: {mean_absolute_error(all_true_mac, all_pred_mac):.2f}\")\n\n    return {\n        \"cls_acc\": accuracy_score(all_true_cls, all_pred_cls),\n        \"cal_mae\": mean_absolute_error(all_true_cal, all_pred_cal),\n        \"mac_mae\": mean_absolute_error(all_true_mac, all_pred_mac)\n    }\n\n\nmetrics = evaluate_model(model, test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:12:08.890995Z","iopub.execute_input":"2025-12-01T19:12:08.891493Z","iopub.status.idle":"2025-12-01T19:12:47.707249Z","shell.execute_reply.started":"2025-12-01T19:12:08.891469Z","shell.execute_reply":"2025-12-01T19:12:47.706523Z"},"editable":false},"outputs":[{"name":"stdout","text":"========== TEST RESULTS ==========\nClassification Accuracy: 0.8377\nCalorie MAE: 0.26\nMacros MAE: 0.37\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"sample = test_dataset[0]\nprint(\"TYPE:\", type(sample))\nprint(\"LENGTH:\", len(sample))\n\nif isinstance(sample, tuple):\n    for i, v in enumerate(sample):\n        print(f\"  Item {i}:\", type(v), v)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:03:26.487526Z","iopub.execute_input":"2025-12-01T19:03:26.488331Z","iopub.status.idle":"2025-12-01T19:03:26.612322Z","shell.execute_reply.started":"2025-12-01T19:03:26.488299Z","shell.execute_reply":"2025-12-01T19:03:26.611721Z"},"editable":false},"outputs":[{"name":"stdout","text":"TYPE: <class 'tuple'>\nLENGTH: 2\n  Item 0: <class 'torch.Tensor'> tensor([[[-1.0733, -1.1075, -1.0562,  ...,  0.6221,  0.7419,  0.7762],\n         [-1.1418, -1.1418, -1.1075,  ...,  0.6221,  0.7077,  0.7762],\n         [-1.2103, -1.1760, -1.1247,  ...,  0.6221,  0.7248,  0.7933],\n         ...,\n         [-1.5357, -1.5528, -1.5014,  ...,  0.3481,  0.4166,  0.4679],\n         [-1.5357, -1.5357, -1.5357,  ...,  0.3309,  0.3823,  0.4679],\n         [-1.5014, -1.5014, -1.5014,  ...,  0.3309,  0.3652,  0.4679]],\n\n        [[-1.0903, -1.0728, -1.0203,  ...,  0.7654,  0.8704,  0.9580],\n         [-1.1253, -1.1078, -1.0553,  ...,  0.7654,  0.8880,  0.9755],\n         [-1.1954, -1.1429, -1.0728,  ...,  0.7654,  0.8880,  0.9930],\n         ...,\n         [-1.4230, -1.4405, -1.4230,  ...,  0.4678,  0.5378,  0.5903],\n         [-1.4230, -1.4230, -1.4230,  ...,  0.4678,  0.5203,  0.5903],\n         [-1.3880, -1.3880, -1.4230,  ...,  0.4678,  0.5028,  0.5553]],\n\n        [[-1.1596, -1.1073, -0.9853,  ...,  1.0365,  1.2108,  1.2805],\n         [-1.1770, -1.1247, -1.0376,  ...,  1.0539,  1.1934,  1.2805],\n         [-1.1596, -1.0898, -1.0550,  ...,  1.0191,  1.1585,  1.2457],\n         ...,\n         [-1.3687, -1.3861, -1.3513,  ...,  0.7576,  0.8274,  0.8622],\n         [-1.3687, -1.3861, -1.3687,  ...,  0.7576,  0.7925,  0.8448],\n         [-1.3513, -1.3513, -1.3687,  ...,  0.7576,  0.7751,  0.8274]]])\n  Item 1: <class 'numpy.int64'> 6\n","output_type":"stream"}],"execution_count":84},{"cell_type":"code","source":"import random\nimport torch.nn.functional as F\n\ndef show_sample_predictions(model, dataset, num_samples=4):\n    model.eval()\n    indices = random.sample(range(len(dataset)), num_samples)\n\n    for idx in indices:\n        \n        image, targets = dataset[idx] \n \n        cls_true = targets[\"class\"]\n        \n        cal_true = targets[\"calories\"].item() if isinstance(targets[\"calories\"], torch.Tensor) else targets[\"calories\"]\n      \n        mac_true = targets[\"macros\"].tolist() if isinstance(targets[\"macros\"], torch.Tensor) else targets[\"macros\"]\n\n\n        img_in = image.unsqueeze(0).to(DEVICE)\n\n        with torch.no_grad():\n            \n            cls_pred, cal_pred_tensor, mac_pred_tensor = model(img_in)\n       \n            cls_pred = torch.argmax(cls_pred, dim=1).item()\n            cal_pred = cal_pred_tensor.item()\n            mac_pred = mac_pred_tensor.squeeze().cpu().numpy()\n\n        plt.figure(figsize=(5, 5))\n\n        plt.imshow(image.permute(1, 2, 0).cpu().numpy()) \n        plt.axis(\"off\")\n        plt.title(\n            f\"True class: {cls_true} | Pred: {cls_pred}\\n\"\n            f\"Cal True: {cal_true:.1f} | Pred: {cal_pred:.1f}\\n\"\n            f\"Macros True: {mac_true}\\n\"\n            f\"Macros Pred: {mac_pred.round(1).tolist()}\"\n        )\n        plt.show()\n\nshow_sample_predictions(model, test_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:30:53.848546Z","iopub.execute_input":"2025-12-01T19:30:53.849150Z","iopub.status.idle":"2025-12-01T19:30:53.943596Z","shell.execute_reply.started":"2025-12-01T19:30:53.849126Z","shell.execute_reply":"2025-12-01T19:30:53.942796Z"},"editable":false},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/4050190736.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mshow_sample_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_47/4050190736.py\u001b[0m in \u001b[0;36mshow_sample_predictions\u001b[0;34m(model, dataset, num_samples)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# --- FIX IS HERE ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Assuming dataset[idx] now returns 4 items: image, class_id, calories, macros_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmac_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# -------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"],"ename":"ValueError","evalue":"not enough values to unpack (expected 4, got 2)","output_type":"error"}],"execution_count":93},{"cell_type":"code","source":"","metadata":{"trusted":true,"editable":false},"outputs":[],"execution_count":null}]}